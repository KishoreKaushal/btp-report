\chapter{Introduction}
\label{ch:introduction}
\pagenumbering{arabic}\hspace{3mm}

This chapter discusses anomaly detection, its use cases and some major challenges.

\section{Anomaly Detection}
\label{sec:anomaly-detection-definition}

Anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.
Typically, the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text.
Anomalies also known as outliers, novelties, noise, deviations and exceptions.

Three broad categories of anomaly detection techniques exist:

\begin{enumerate}
    \item Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal by looking for instances that seem to fit least to the remainder of the data set.
    \item Supervised anomaly detection techniques require a data set that has been labeled as "normal" and "abnormal" and involves training a classifier (the key difference to many other statistical classification problems is the inherently unbalanced nature of outlier detection).
    \item Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set, and then test the likelihood of a test instance to be generated by the learnt model.
\end{enumerate}

We will restrict ourselves to unsupervised anomaly detection and semi-supervised anomaly detection problem.

\section{Use Cases}
\label{sec:anomaly-detection-use-cases}

The ability to detect anomalies has significant relevance, and anomalies often provides critical and actionable information in various application domains.

Identification of potential outliers is important for the following reasons: \cite{EngineeringStatsHandbook}

\begin{enumerate}
    \item An outlier may indicate bad data.
    For example, the data may have been coded incorrectly, or an experiment may not have been run correctly.
    If it can be determined that an outlying point is in fact erroneous, then the outlying value should be deleted from the analysis (or corrected if possible).
    \item In some cases, it may not be possible to determine if an outlying point is bad data.
    Outliers may be due to random variation or may indicate something scientifically interesting.
    In any event, we typically do not want to simply delete the outlying observation.
\end{enumerate}

For example, anomalies in credit card transactions could signify fraudulent use of credit cards.
An anomalous spot in an astronomy image could indicate the discovery of a new star.
An unusual computer network traffic pattern could stand for unauthorised access.
These applications demand anomaly detection algorithms with high detection accuracy and fast execution.

\section{Challenges}
\label{sec:anomaly-detection-challenges}


\subsection{Masking and Swamping}
\label{subsec:masking-and-swamping}

Masking and swamping is the biggest problem affecting any anomaly detection algorithm.

Masking is the existence of too many anomalies concealing their own presence.
It happens when anomaly clusters become large and dense.
For example, if we are testing for a single outlier when there are in fact more outliers, these additional outliers may influence the value of the test statistic enough so that no points are declared as outliers.

On the other hand, swamping refers to situations where normal instances are wrongly identifying as anomalies.
It happens when the number of normal instances increases, or they become more scattered.
For example, if we are testing for two or more outliers when there is in fact only a single outlier, both points may be declared outliers.

Masking is one reason that trying to apply a single outlier test sequentially can fail.
For example, if there are multiple outliers, masking may cause the outlier test for the first outlier to return a conclusion of no outliers.
So the testing is not performed for any additional outliers.

\subsection{Concept drift}
\label{subsec:concept-drift}

In the case of streaming data, the anomaly context can change over time.
For example, consider a user's behaviour change from one system to another.
The anomaly detection algorithm should adapt to this change in the behaviour of the external agent.
This deviation of the normal behaviour time to time is called concept drift.
Any online anomaly detection algorithm must have a way to deal with this.

\subsection{Miscellaneous}
\label{subsec:misc-challenges}

Apart from the above conceptual challenges, here are some general challenges pointed out by Vatsal et al. \cite{NIPS2019_9710}

\paragraph{High dimensional, heterogeneous data:}
The data collected could contains measurements of metrics like cpu usage, memory, bandwidth, temperature, in addition to categorical data such as day of the week, geographic location, OS type. 
This makes finding an accurate generative model for the data challenging. 
The metrics might be captured in different units, hence algorithms that are unit-agnostic are preferable. 
The algorithm needs to scale to high dimensional data.

\paragraph{Scarce labels:} Most of the data are unlabeled. Generating labels is time and effort intensive
and requires domain knowledge. Hence supervised methods are a non-starter, and even
tuning too many hyper-parameters of unsupervised algorithms could be challenging.

\paragraph{Irrelevant attributes:}
Often an anomaly manifests itself in a relatively small number of attributes among the large number being monitored. 
For instance, a single machine in a large datacenter might be compromised and behave abnormally.

\section{Organization of The Report}
\label{sec:organization-of-the-report}

This chapter [\ref{ch:introduction}] provides a background for the topics covered in this report.
We provided a description of anomaly detection problem and discussed some use cases.
Then we discussed some challenges to anomaly detection problem: masking, swamping and concept drift.
In the next chapter [\ref{ch:isolation-forest}] we will discuss a very efficient ensemble method Isolation Forest for anomaly detection.
In chapter [\ref{ch:pidforest}] we will discuss another ensemble method PIDForest which has been recently developed.
The major drawback of the above mentioned algorithms is that they are used in offline setting without dealing with concept drift.
Most of the anomaly detection algorithm is offline and fail to address the problem of concept drift.
In chapter [\ref{ch:contributions}] we will present some methods to address these issues.
In chapter [\ref{ch:ai-image-compression}] we will review our work did till mid-sem.
And finally in chapter [\ref{ch:conclusion-future-work}], we conclude with some future works.

\vspace{2em}

\textbf{Code Repository: } \url{https://github.com/KishoreKaushal/AnomalyDetection}

\textbf{Report Repository: } \url{https://github.com/KishoreKaushal/btp-report}
