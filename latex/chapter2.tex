\chapter{Isolation Forest}
\label{ch:isolation-forest}

\section{Isolation based anomaly detection}
\label{sec:isolation-based-anomaly-detection}

Isolation is the process or fact of isolating or being isolated.
The authors of \cite{10.1145/2133360.2133363} proposed an isolation based anomaly detection which takes advantage of two quantitative properties of anomalies:
\begin{enumerate}
    \item They are the minority consisting of few instances.
    \item They have attribute-values that are very different from those of normal instances.
\end{enumerate}

Hence, anomalies are 'few and different' which make them more susceptible to a mechanism we called Isolation.
Isolation can be implemented by any means that separates instances.
Lui et al. \cite{10.1145/2133360.2133363} proposed to use a binary tree structure called isolation tree (iTree) which can be constructed effectively to isolate instances.
Because of the susceptibility to isolation, anomalies are more likely to be isolated closer to the root of an iTree;
whereas normal points are more likely to be isolated at the deeper end of an iTree.

The proposed method, called Isolation Forest (iForest) builds an ensemble  builds an ensemble of iTrees for a given data set.
Anomalies are those instances which have short average path lengths on the iTrees.
There are two training parameters and one evaluation parameter in this method: the training parameters are the number of trees to build and subsampling size.
The evaluation parameter is the tree height limit during evaluation.

\section{Training Stage}
\label{sec:iforest-training}

Formally, isolation tree is defined as follows:

\begin{defn}
    Let T be a node of an isolation tree.
    T is either an external-node with no child, or an internal-node with one test and exactly two daughter nodes $(T_l, T_r)$.
    A test at node $T$ consists of an attribute $q$ and a split value $p$ such that the test $q < p$ determines the traversal of a data point to either $T_l$ or $T_r$.
    Let X = $\{x_1, ..., x_n\}$ be the given data set of a d-variate distribution.
    A sample of instances X'$\subset$ X is used to build an isolation tree$^{[\ref{alg:iTree}]}$.
    We recursively divide X' by randomly selecting an attribute q and a split value p, until either: i) Node has only one instance ii) Or, all data at the node have the same values.
\end{defn}


\begin{defn}
    Isolation forest is defined as 4-tuple $(X, t, \psi, S)$ where
    \vspace{-1em}
    \begin{itemize}
        \setlength\itemsep{-1em}
        \item X is input data,
        \item t is number of trees,
        \item $\psi$ is subsampling size and
        \item S is the set of isolation trees.
    \end{itemize}
    \vspace{-1em}
    The elements of set S is constructed$^{[\ref{alg:iForest}]}$ by sampling $\psi$ instances from X without replacement.
\end{defn}

\vspace{1em}
\begin{algorithm}[H]
    \caption{$iForest(X,t,\psi)$}\label{alg:iForest}
    \setstretch{1.2}
    \SetAlgoLined
    \KwComplexity{Time - $O(t\psi^2)$, Space - $O(t\psi)$}
    \KwInput{$X$ - input data, $t$ - number of trees, $\psi$ - subsampling size}
    \KwOutput{List of $iTrees$}

    $Forest \: \leftarrow $ EmptyList

    \For {$i = 1$ to $t$}{
        $X' \: \leftarrow \: sampleWithoutReplacement(X,\psi)$

        $Forest \: \leftarrow \: Forest \cup iTree(X')$
    }

    \Return{Forest}
\end{algorithm}

\vspace{1em}
\begin{algorithm}[H]
    \caption{$iTree(X)$}\label{alg:iTree}
    \setstretch{1.2}
    \SetAlgoLined
    \KwComplexity{Time - $O(\psi^2)$, Space - $O(\psi)$}
    \KwInput{$X$ - input data}
    \KwOutput{an $iTree$}

    q $\leftarrow \: RandomChoice(X.attributes)$

    p $\leftarrow \: RandomNumber(X[$splitAttr$].min(), X[$splittAttr$].max())$

    tree $\leftarrow$ Node \{ left $\leftarrow$ None, right $\leftarrow$ None, size $\leftarrow \: X.size$

    \qquad\qquad\qquad splitAttr $\leftarrow$ q, splitVal $\leftarrow$ p\}

    \If{X.size $>$ 1 and X[splitAttr].numUnique() $>$ 1}{
        $X_{l} \: \leftarrow  \: X.where(q < p)$

        $X_{r} \: \leftarrow  \: X.where(q \geq p)$

        tree.left $\leftarrow \: iTree(X_{l})$

        tree.right $\leftarrow \: iTree(X_{r})$
    }

    \Return{tree}
\end{algorithm}
\vspace{1em}

\section{Evaluation Stage}
\label{sec:iforest-evaluation}


\vspace{1em}
\begin{algorithm}[H]
    \caption{$PathLength(x)$}\label{alg:PathLength}
    \DontPrintSemicolon
    \setstretch{1.2}
    \SetAlgoLined
    \KwComplexity{Time - $O(t\psi)$, Space - $O(1)$}
    \KwInput{$x$ - input instance, $T$ - an iTree, $hlim$ - height limit, $e$ - current path length to be initialized to zero when called first time}
    \KwOutput{path length of $x$}

    \If{ (T.right is None) and (T.left is none) and (e $\geq$ hlim)}{

        \Return $e + c(T.size)$ \tcp*{c(...) is defined in Equation 1}

    }

    $a \: \leftarrow \: T.splitAttr$

    \If{ $x[a] < T.splitVal$}{
        \Return  $PathLength(x, T.left, hlim, e + 1)$
    }
    \Else{
        \Return  $PathLength(x, T.right, hlim, e + 1)$
    }
\end{algorithm}
\pagebreak

In the evaluation stage$^{[\ref{alg:PathLength}]}$, a single path length $h(x)$ is derived by counting the number of edges $e$ from the root node to an external node as instance $x$ traverses through an iTree.
When the traversal reaches a predefined height limit $hlim$, the return value is $e$ plus an adjustment $c(size)$.
This adjustment accounts for estimating an average path length of a random sub-tree which could be constructed using data of $size$ beyond the tree height limit.
When $h(x)$ is obtained for each tree of the ensemble, an anomaly score is computed.
The anomaly score and the adjustment $c(size)$ are defined as follows.






\begin{defn}

\end{defn}




This chapter provided details of the some of the existing
distributed algorithms for constructing a CDS in wireless ad-hoc
networks. The results of these evaluations are summarized in table. In next chapter, we discuss our distributed
Algorithm I, for constructing a small backbone in ad-hoc wireless
network.

